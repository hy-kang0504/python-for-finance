{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9ebd67",
   "metadata": {},
   "source": [
    "# Predict Economic Regimes\n",
    "\n",
    "In this notebook, we will use codes written in the 'FRED_01_data_preparation' notebook to fetch macro indicators. Remeber we downloaded the data as csv. Then we will use scikit learn to see how machine learning can used to predict recessions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "add228fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import getdata as gd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3325d0f",
   "metadata": {},
   "source": [
    "## Train data\n",
    "\n",
    "We will first fetch the fred data and set independent and dependent variables. \n",
    "\n",
    "Then, we are going to use SVC, DecisionTreeClassifier, RandomForestClassifier and GradientBoostingClassifiers as classifiers to find out which method has the higest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "198209e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74062dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fred_data.csv', index_col = 'Date', parse_dates = ['Date'])\n",
    "\n",
    "independent_variables = df.columns[:-1]\n",
    "X = df[independent_variables] \n",
    "y = df['Regime']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "225ca442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 30s, sys: 5.45 s, total: 19min 35s\n",
      "Wall time: 35min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline(steps=[('clf', SVC())])\n",
    "\n",
    "params_grid = [{\n",
    "                'clf':[SVC()],\n",
    "                'clf__C': [1, 10],\n",
    "                'clf__gamma': ['scale', 'auto'],\n",
    "                },\n",
    "                {\n",
    "                'clf': [DecisionTreeClassifier()],\n",
    "                'clf__max_depth': [3, 5, 10, 20],\n",
    "                'clf__splitter': ['best', 'random'],\n",
    "                'clf__min_samples_split': [2, 3, 5],\n",
    "                },\n",
    "                {\n",
    "                'clf': [RandomForestClassifier()],\n",
    "                'clf__max_depth': [3, 5, 10, 20],\n",
    "                'clf__n_estimators': [100,200,400],\n",
    "                },\n",
    "                {\n",
    "                'clf': [GradientBoostingClassifier()],\n",
    "                'clf__max_depth': [3, 5, 10, 20],\n",
    "                'clf__min_samples_split': [2, 3, 5],\n",
    "                'clf__n_estimators': [100,200,400],\n",
    "                },\n",
    "                {\n",
    "                'clf': [LogisticRegression()],\n",
    "                'clf__solver': ['saga'],\n",
    "                'clf__max_iter': [1000],                    \n",
    "                }                \n",
    "              ]\n",
    "\n",
    "grid = GridSearchCV(pipe, params_grid, cv=5)\n",
    "clf = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d09b30",
   "metadata": {},
   "source": [
    "Let's see how each classifer did with the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48a53255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "param_clf\n",
       "RandomForestClassifier(max_depth=10)    0.965111\n",
       "GradientBoostingClassifier()            0.964424\n",
       "LogisticRegression()                    0.953872\n",
       "DecisionTreeClassifier()                0.948205\n",
       "SVC()                                   0.908217\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(clf.cv_results_).sort_values(by=['rank_test_score']).iloc[:,4:]\n",
    "res['param_clf'] = res['param_clf'].astype(str)\n",
    "res.groupby('param_clf')['mean_test_score'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50035c50",
   "metadata": {},
   "source": [
    "They did pretty well with all of them having scored higher than 0.9 accuracy.\n",
    "\n",
    "Let's check top 5 parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b697e886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__gamma</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_clf__min_samples_split</th>\n",
       "      <th>param_clf__splitter</th>\n",
       "      <th>param_clf__n_estimators</th>\n",
       "      <th>param_clf__max_iter</th>\n",
       "      <th>param_clf__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': GradientBoostingClassifier(), 'clf__ma...</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.971618</td>\n",
       "      <td>0.015255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestClassifier(max_depth=10)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': RandomForestClassifier(max_depth=10), ...</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.971618</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': GradientBoostingClassifier(), 'clf__ma...</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.971602</td>\n",
       "      <td>0.017234</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': GradientBoostingClassifier(), 'clf__ma...</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.971602</td>\n",
       "      <td>0.017234</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': GradientBoostingClassifier(), 'clf__ma...</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.982301</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.971602</td>\n",
       "      <td>0.014249</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               param_clf param_clf__C param_clf__gamma  \\\n",
       "41          GradientBoostingClassifier()          NaN              NaN   \n",
       "34  RandomForestClassifier(max_depth=10)          NaN              NaN   \n",
       "47          GradientBoostingClassifier()          NaN              NaN   \n",
       "46          GradientBoostingClassifier()          NaN              NaN   \n",
       "42          GradientBoostingClassifier()          NaN              NaN   \n",
       "\n",
       "   param_clf__max_depth param_clf__min_samples_split param_clf__splitter  \\\n",
       "41                    3                            2                 NaN   \n",
       "34                   10                          NaN                 NaN   \n",
       "47                    3                            5                 NaN   \n",
       "46                    3                            5                 NaN   \n",
       "42                    3                            2                 NaN   \n",
       "\n",
       "   param_clf__n_estimators param_clf__max_iter param_clf__solver  \\\n",
       "41                     200                 NaN               NaN   \n",
       "34                     100                 NaN               NaN   \n",
       "47                     200                 NaN               NaN   \n",
       "46                     100                 NaN               NaN   \n",
       "42                     400                 NaN               NaN   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "41  {'clf': GradientBoostingClassifier(), 'clf__ma...           0.991150   \n",
       "34  {'clf': RandomForestClassifier(max_depth=10), ...           0.973451   \n",
       "47  {'clf': GradientBoostingClassifier(), 'clf__ma...           0.991150   \n",
       "46  {'clf': GradientBoostingClassifier(), 'clf__ma...           0.991150   \n",
       "42  {'clf': GradientBoostingClassifier(), 'clf__ma...           0.991150   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "41           0.946903           0.982301           0.973451   \n",
       "34           0.973451           0.964602           0.982301   \n",
       "47           0.946903           0.982301           0.982301   \n",
       "46           0.946903           0.982301           0.982301   \n",
       "42           0.955752           0.982301           0.973451   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "41           0.964286         0.971618        0.015255                1  \n",
       "34           0.964286         0.971618        0.006691                1  \n",
       "47           0.955357         0.971602        0.017234                3  \n",
       "46           0.955357         0.971602        0.017234                3  \n",
       "42           0.955357         0.971602        0.014249                3  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597c734",
   "metadata": {},
   "source": [
    "## Test data\n",
    "\n",
    "Let's take these 5 classifiers and parameters and test with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "70d5cd6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset scores using GradientBoostingClassifier(n_estimators=200)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       164\n",
      "         1.0       0.86      0.79      0.83        24\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.92      0.89      0.90       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n",
      "Test dataset scores using RandomForestClassifier(max_depth=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97       164\n",
      "         1.0       0.89      0.71      0.79        24\n",
      "\n",
      "    accuracy                           0.95       188\n",
      "   macro avg       0.93      0.85      0.88       188\n",
      "weighted avg       0.95      0.95      0.95       188\n",
      "\n",
      "Test dataset scores using GradientBoostingClassifier(min_samples_split=5, n_estimators=200)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       164\n",
      "         1.0       0.86      0.79      0.83        24\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.92      0.89      0.90       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n",
      "Test dataset scores using GradientBoostingClassifier(min_samples_split=5)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       164\n",
      "         1.0       0.86      0.79      0.83        24\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.92      0.89      0.90       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n",
      "Test dataset scores using GradientBoostingClassifier(n_estimators=400)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       164\n",
      "         1.0       0.86      0.79      0.83        24\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.92      0.89      0.90       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    GradientBoostingClassifier(min_samples_split=2, max_depth=3, n_estimators=200),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=100),\n",
    "    GradientBoostingClassifier(min_samples_split=5, max_depth=3, n_estimators=200),\n",
    "    GradientBoostingClassifier(min_samples_split=5, max_depth=3, n_estimators=100),\n",
    "    GradientBoostingClassifier(min_samples_split=2, max_depth=3, n_estimators=400),    \n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test dataset scores using {}'.format(model))\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1a730",
   "metadata": {},
   "source": [
    "We can see that these models yield 0.96 accuracy on the test dataset.\n",
    "\n",
    "Let's try the same thing, but with default settings for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cec4c37b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset scores using RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       164\n",
      "         1.0       0.89      0.67      0.76        24\n",
      "\n",
      "    accuracy                           0.95       188\n",
      "   macro avg       0.92      0.83      0.87       188\n",
      "weighted avg       0.94      0.95      0.94       188\n",
      "\n",
      "Test dataset scores using GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       164\n",
      "         1.0       0.86      0.79      0.83        24\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.92      0.89      0.90       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n",
      "Test dataset scores using LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97       164\n",
      "         1.0       0.94      0.62      0.75        24\n",
      "\n",
      "    accuracy                           0.95       188\n",
      "   macro avg       0.94      0.81      0.86       188\n",
      "weighted avg       0.95      0.95      0.94       188\n",
      "\n",
      "Test dataset scores using DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       164\n",
      "         1.0       0.86      0.79      0.83        24\n",
      "\n",
      "    accuracy                           0.96       188\n",
      "   macro avg       0.92      0.89      0.90       188\n",
      "weighted avg       0.96      0.96      0.96       188\n",
      "\n",
      "Test dataset scores using SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93       164\n",
      "         1.0       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.87       188\n",
      "   macro avg       0.44      0.50      0.47       188\n",
      "weighted avg       0.76      0.87      0.81       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d_models = [\n",
    "    RandomForestClassifier(),    \n",
    "    GradientBoostingClassifier(),            \n",
    "    LogisticRegression(),                    \n",
    "    DecisionTreeClassifier(),                \n",
    "    SVC()                                   \n",
    "]\n",
    "\n",
    "for d_model in d_models:\n",
    "    d_model.fit(X_train, y_train)\n",
    "    y_pred_d = d_model.predict(X_test)\n",
    "    print('Test dataset scores using {}'.format(d_model))\n",
    "    print(metrics.classification_report(y_test, y_pred_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133b7b9",
   "metadata": {},
   "source": [
    "The classifiers with default settings yield similar accuracy scores to those of the hyper-tuned classifiers except SVC. Hyper-tuned classifiers have done a better job in terms of f1.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
